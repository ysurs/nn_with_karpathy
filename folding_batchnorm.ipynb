{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jb7JdC2rHMzLM1mKTaxzifqn_pe--Kwv",
      "authorship_tag": "ABX9TyMbYK/f6zVy3p1lJt+kHwUW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysurs/nn_with_karpathy/blob/main/folding_batchnorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "metadata": {
        "id": "E-E5-rbwmlXW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in all the words\n",
        "words = open('/content/drive/MyDrive/building_makemore/names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueV8bgCkndYl",
        "outputId": "a96eeffb-0e60-4901-fb12-2d156b0f47c0"
      },
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qip3GPsonikb",
        "outputId": "017fae82-4664-4427-db6f-88f22a6c2d99"
      },
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "block_size=3"
      ],
      "metadata": {
        "id": "igTwRJJpnvO_"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):  \n",
        "  X, Y = [], []\n",
        "  \n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gzvf4HsppP8X",
        "outputId": "c4866beb-0dbc-427f-a712-17caee2ee6f5"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuhYreDmFlDZ",
        "outputId": "30de1615-0315-4e59-fef9-b9c5224264ff"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([182625, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Ytr.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ayfbOnvFtjB",
        "outputId": "0cc2690d-7497-475b-e4ae-99e14d7486d2"
      },
      "execution_count": 269,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([182625])"
            ]
          },
          "metadata": {},
          "execution_count": 269
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pytorchfying things and building a 3 layered mlp"
      ],
      "metadata": {
        "id": "mKar0q9uFxF9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Linear:\n",
        "\n",
        "  def __init__(self,fanin,fanout,bias=True):\n",
        "   self.weight=torch.randn((fanin,fanout))/(fanin)**0.5\n",
        "   self.bias=torch.zeros(fanout) if bias==True else None   ## bias is usually intialised to zero in case to speed up training\n",
        "\n",
        "\n",
        "  def __call__(self,x):\n",
        "    self.out = x@self.weight\n",
        "    if self.bias is not None:\n",
        "      self.out+=self.bias\n",
        "    return self.out\n",
        "\n",
        "  \n",
        "  def parameters(self):\n",
        "    return [self.weight]+([] if self.bias is None else [self.bias])\n"
      ],
      "metadata": {
        "id": "2NXaZUp8Fvln"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class batchnorm1d:\n",
        "\n",
        "  def __init__(self,dim,eps=1e-5,momentum=0.1):\n",
        "    self.eps=eps\n",
        "    self.momentum=momentum\n",
        "    self.training=True\n",
        "    self.gamma=torch.ones(dim)\n",
        "    self.beta=torch.zeros(dim)\n",
        "\n",
        "    self.running_mean=torch.zeros(dim)\n",
        "    self.running_var=torch.ones(dim)\n",
        "\n",
        "  def __call__(self,h):\n",
        "    \n",
        "    if self.training==True:\n",
        "      hmean=h.mean(0,keepdims=True)\n",
        "      hvar=h.var(0,keepdims=True)\n",
        "    else:\n",
        "      hmean=self.running_mean\n",
        "      hvar=self.running_var\n",
        "    \n",
        "    hnorm=(h-hmean)/((hvar+self.eps)**0.5)\n",
        "    self.out=self.gamma*hnorm+self.beta\n",
        "\n",
        "    if self.training:\n",
        "      with torch.no_grad():\n",
        "       self.running_mean=(1-self.momentum)*self.running_mean +(self.momentum)*hmean\n",
        "       self.running_var=(1-self.momentum)*self.running_var +(self.momentum)*hvar\n",
        "\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return [self.gamma,self.beta]\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "atz-AiXsLvh-"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class tanh:\n",
        "\n",
        "  def __call__(self,x):\n",
        "    self.out=torch.tanh(x)\n",
        "    return self.out\n",
        "  \n",
        "  def parameters(self):\n",
        "    return []"
      ],
      "metadata": {
        "id": "V-8WHLob0-yF"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 100 # the number of neurons in the hidden layer of the MLP\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility"
      ],
      "metadata": {
        "id": "6vWvEg3f1bEo"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "C = torch.randn((vocab_size, n_embd),            generator=g)"
      ],
      "metadata": {
        "id": "8PAbWn7S1bKZ"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layers = [\n",
        "  Linear(n_embd * block_size, n_hidden,bias=False), batchnorm1d(n_hidden), tanh(),\n",
        "  Linear(           n_hidden, n_hidden, bias=False), batchnorm1d(n_hidden), tanh(),\n",
        "  Linear(           n_hidden, n_hidden, bias=False), batchnorm1d(n_hidden), tanh(),\n",
        "  Linear(           n_hidden, vocab_size, bias=False), batchnorm1d(vocab_size),\n",
        "]"
      ],
      "metadata": {
        "id": "P7zmjDdL2h6j"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  \n",
        "  layers[-1].gamma*=0.1 ## making the output layer less confident\n",
        "\n",
        "  for layer in layers[:-1]:\n",
        "\n",
        "    if isinstance(layer,Linear):\n",
        "      layer.weight*=5/3          ## Kiaming initialisation"
      ],
      "metadata": {
        "id": "R3R5I5D_5EUT"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters=[C]+[p for layer in layers for p in layer.parameters()]\n",
        "\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "id": "6eCkChIM6np0"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training needs to be done now\n",
        "\n",
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "ud = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "  \n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "\n",
        "  emb=C[Xb]\n",
        "  x=emb.view(emb.shape[0],-1)\n",
        "\n",
        "  for layer in layers:\n",
        "    x=layer(x)\n",
        "  \n",
        "  loss=F.cross_entropy(x,Yb)\n",
        "\n",
        "  # backward pass\n",
        "  for layer in layers:\n",
        "      layer.out.retain_grad() # AFTER_DEBUG: would take out retain_graph\n",
        "    \n",
        "      #print(layer)\n",
        "  for p in parameters:\n",
        "    p.grad=None\n",
        "  #print(loss)\n",
        "  #loss.requires_grad=True\n",
        "  loss.backward()\n",
        "\n",
        "  # update\n",
        "  #with torch.no_grad():\n",
        "  lr = 0.1 if i < 150000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "  \n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        "  with torch.no_grad():\n",
        "    ud.append([((lr*p.grad).std() / p.data.std()).log10().item() for p in parameters])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rBythID_rss",
        "outputId": "4b6f171e-4f36-4b36-c6f5-4618e7e16692"
      },
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0/ 200000: 3.2818\n",
            "  10000/ 200000: 2.4163\n",
            "  20000/ 200000: 1.9671\n",
            "  30000/ 200000: 1.9336\n",
            "  40000/ 200000: 2.3348\n",
            "  50000/ 200000: 2.3135\n",
            "  60000/ 200000: 1.7474\n",
            "  70000/ 200000: 2.1601\n",
            "  80000/ 200000: 2.0903\n",
            "  90000/ 200000: 1.9366\n",
            " 100000/ 200000: 1.6916\n",
            " 110000/ 200000: 2.0548\n",
            " 120000/ 200000: 1.8437\n",
            " 130000/ 200000: 1.8865\n",
            " 140000/ 200000: 2.0312\n",
            " 150000/ 200000: 1.8649\n",
            " 160000/ 200000: 1.9336\n",
            " 170000/ 200000: 2.3135\n",
            " 180000/ 200000: 2.0979\n",
            " 190000/ 200000: 1.9938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad() # this decorator disables gradient tracking\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  x = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  for layer in layers:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "# put layers into eval mode\n",
        "for layer in layers:\n",
        "  layer.training = False\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4G5Fl_721gN",
        "outputId": "ee85f8ac-1c5e-4f0d-d5a3-775dc747300c"
      },
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.026998996734619\n",
            "val 2.0902256965637207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fold(linear_batchnorm):\n",
        "  with torch.no_grad():\n",
        "    only_linear=[]\n",
        "    for i in range(len(linear_batchnorm)):\n",
        "\n",
        "      if isinstance(linear_batchnorm[i],Linear):\n",
        "        linear_batchnorm[i].weight=((layers[i].parameters())[0]*layers[i+1].parameters()[0])/(layers[i+1].running_var+layers[i+1].eps)**0.5\n",
        "        linear_batchnorm[i].bias=-(((layers[i+1].running_mean)*layers[i+1].parameters()[0])/(layers[i+1].running_var+layers[i+1].eps)**0.5)+layers[i+1].parameters()[1]\n",
        "        only_linear.append(linear_batchnorm[i])\n",
        "      if isinstance(linear_batchnorm[i],tanh):\n",
        "        only_linear.append(linear_batchnorm[i])\n",
        "  return only_linear"
      ],
      "metadata": {
        "id": "dISyozzU8ZSt"
      },
      "execution_count": 277,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad() # this decorator disables gradient tracking\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  x = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  folded_layers=fold(layers)\n",
        "\n",
        "  for layer in folded_layers:\n",
        "    x = layer(x)\n",
        "  loss = F.cross_entropy(x, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX00guv93K-g",
        "outputId": "c776847b-72ec-4ef6-d35e-ee0401fc6b50"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.0272374153137207\n",
            "val 3.074354887008667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting different values after normal batch norm and folding batch norm, needs some rechecking"
      ],
      "metadata": {
        "id": "5SMg8GAyo18v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*****"
      ],
      "metadata": {
        "id": "4BaLTlOdxNte"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rough shape checking below"
      ],
      "metadata": {
        "id": "w8GzRyvdxQxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(layers[0].parameters())#[0].sha\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVacL7IV3Y1P",
        "outputId": "a54fd906-8626-4381-bff9-06f2b6dbf9cf"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 0.4556, -0.5162,  0.9341,  ..., -0.1871, -0.3436, -0.4096],\n",
              "         [-0.0550, -0.1066,  0.1744,  ...,  0.0784,  0.2280,  0.6458],\n",
              "         [-0.3999, -0.4941,  0.3786,  ..., -0.2446,  0.3587, -0.0846],\n",
              "         ...,\n",
              "         [-0.6333, -0.7574, -0.0051,  ...,  0.0594,  0.6658,  0.1757],\n",
              "         [ 0.3074,  0.1121,  0.2378,  ..., -0.3029, -0.7110,  0.6990],\n",
              "         [-0.4368,  0.3691,  0.5114,  ...,  0.6087,  0.0854, -0.2348]],\n",
              "        requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(layers[1].running_mean).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VszcKn5e9Aqp",
        "outputId": "2fcded92-a212-4b5a-e57d-0ecea24f0657"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layers[0].weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4adFnfDIDeKt",
        "outputId": "9a68ab3d-d5c9-4014-c269-a3c800675924"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4556, -0.5162,  0.9341,  ..., -0.1871, -0.3436, -0.4096],\n",
              "        [-0.0550, -0.1066,  0.1744,  ...,  0.0784,  0.2280,  0.6458],\n",
              "        [-0.3999, -0.4941,  0.3786,  ..., -0.2446,  0.3587, -0.0846],\n",
              "        ...,\n",
              "        [-0.6333, -0.7574, -0.0051,  ...,  0.0594,  0.6658,  0.1757],\n",
              "        [ 0.3074,  0.1121,  0.2378,  ..., -0.3029, -0.7110,  0.6990],\n",
              "        [-0.4368,  0.3691,  0.5114,  ...,  0.6087,  0.0854, -0.2348]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "((layers[0].parameters())[0]*layers[1].parameters()[0])/(layers[1].running_var+layers[1].eps)**0.5#.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHStnmFeAmjR",
        "outputId": "a3b1c13e-56e4-48db-a3b8-e6c5ccafb4c1"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3376, -0.3569,  0.5789,  ..., -0.1201, -0.2349, -0.3138],\n",
              "        [-0.0407, -0.0737,  0.1081,  ...,  0.0503,  0.1559,  0.4948],\n",
              "        [-0.2963, -0.3416,  0.2346,  ..., -0.1570,  0.2453, -0.0648],\n",
              "        ...,\n",
              "        [-0.4692, -0.5237, -0.0031,  ...,  0.0381,  0.4553,  0.1346],\n",
              "        [ 0.2277,  0.0775,  0.1474,  ..., -0.1944, -0.4862,  0.5356],\n",
              "        [-0.3236,  0.2552,  0.3170,  ...,  0.3907,  0.0584, -0.1799]],\n",
              "       grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "((layers[1].running_mean)*layers[1].parameters()[0])/(layers[1].running_var+layers[1].eps)**0.5#.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebLit6dTDziG",
        "outputId": "978a5bbf-2e27-4683-a22c-0684fa5e15bb"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.3109, -0.5712,  0.0744,  1.7327, -0.3876, -0.0088,  1.3397,  0.8394,\n",
              "          0.7448,  1.5963, -0.5540, -1.4288, -1.5064,  1.6359,  1.3002,  0.5130,\n",
              "          0.3724,  0.0935,  0.5197, -0.7148, -0.8239, -0.0983, -1.0260,  0.0917,\n",
              "          0.6817,  0.4311, -1.2134,  1.9022,  0.2278,  0.4701,  0.4133,  0.0253,\n",
              "         -0.1466, -0.4083,  0.2230,  0.4810,  0.2815,  0.2737,  1.8236, -0.4514,\n",
              "         -0.3458, -0.7911,  0.8122,  0.3471, -0.7148, -0.0382,  0.2791,  0.0629,\n",
              "         -0.8876,  1.2558, -1.0734,  1.1313, -0.0658, -1.5244,  0.5124,  0.3266,\n",
              "          0.1267, -1.4845,  0.1201,  1.4262, -1.2011, -0.8255, -0.6270,  0.7721,\n",
              "         -0.2698, -0.9140,  0.2299,  0.6089,  0.4187,  0.5998, -0.0999, -0.5497,\n",
              "         -0.7161, -0.2868, -0.3372, -1.1187, -0.0772, -0.3294, -0.1829, -2.7382,\n",
              "          0.5173, -0.2464,  0.6587, -1.2862, -0.3789,  0.2041,  0.5631, -1.2353,\n",
              "         -0.5645, -0.0864, -0.1272,  0.6849,  2.3741, -0.5449, -0.3802,  0.9762,\n",
              "          1.2386, -0.0829,  0.4371,  0.4813]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(layers[1].parameters()[0]).shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ssYKx46EGkj",
        "outputId": "1d101e85-f656-4b2f-c467-6b9c39e5ab78"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([100])"
            ]
          },
          "metadata": {},
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([1,2,3])*torch.tensor([[1,2,3]])#.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cY7lCdmENIi",
        "outputId": "70b453ac-0b7c-4ce3-e6ce-5d23d7987116"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 4, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 193
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(layers[1].parameters()[0])*(layers[0].parameters()[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-v4049SATPP",
        "outputId": "b60d0140-6d8d-4216-d3bc-4c2621aed102"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7256, -0.8731,  1.6219,  ..., -0.2843, -0.5297, -0.7736],\n",
              "        [-0.0875, -0.1803,  0.3027,  ...,  0.1191,  0.3515,  1.2199],\n",
              "        [-0.6368, -0.8357,  0.6573,  ..., -0.3717,  0.5530, -0.1598],\n",
              "        ...,\n",
              "        [-1.0086, -1.2811, -0.0088,  ...,  0.0902,  1.0265,  0.3319],\n",
              "        [ 0.4895,  0.1896,  0.4129,  ..., -0.4602, -1.0963,  1.3203],\n",
              "        [-0.6956,  0.6243,  0.8881,  ...,  0.9247,  0.1316, -0.4435]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 195
        }
      ]
    }
  ]
}