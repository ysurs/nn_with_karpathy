{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1dP9cp6vQt5LR_yvy0k9pCO1e43D-GscD",
      "authorship_tag": "ABX9TyMe2ynaMezFRKsjF3EYn1BD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysurs/nn_with_karpathy/blob/main/batchnorm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ddRo6QSI60Aj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt # for making figures\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read in all the words\n",
        "words = open('/content/drive/MyDrive/building_makemore/names.txt', 'r').read().splitlines()\n",
        "words[:8]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdNnbu1k8BKs",
        "outputId": "57b9dc1e-8aec-4179-d6a8-8f7b921bd1da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['emma', 'olivia', 'ava', 'isabella', 'sophia', 'charlotte', 'mia', 'amelia']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the vocabulary of characters and mappings to/from integers\n",
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s,i in stoi.items()}\n",
        "vocab_size = len(itos)\n",
        "print(itos)\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y5HEbkp8O8x",
        "outputId": "3d3843ca-b735-47e8-f122-aae4ba48ec73"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# build the dataset\n",
        "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
        "\n",
        "def build_dataset(words):  \n",
        "  X, Y = [], []\n",
        "  \n",
        "  for w in words:\n",
        "    context = [0] * block_size\n",
        "    for ch in w + '.':\n",
        "      ix = stoi[ch]\n",
        "      X.append(context)\n",
        "      Y.append(ix)\n",
        "      context = context[1:] + [ix] # crop and append\n",
        "\n",
        "  X = torch.tensor(X)\n",
        "  Y = torch.tensor(Y)\n",
        "  print(X.shape, Y.shape)\n",
        "  return X, Y\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "random.shuffle(words)\n",
        "n1 = int(0.8*len(words))\n",
        "n2 = int(0.9*len(words))\n",
        "\n",
        "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
        "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
        "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlQl-bXm8TJ6",
        "outputId": "640eb106-e4ef-41e8-f99f-680ecb48cb08"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([182625, 3]) torch.Size([182625])\n",
            "torch.Size([22655, 3]) torch.Size([22655])\n",
            "torch.Size([22866, 3]) torch.Size([22866])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP revisited\n",
        "n_embd = 10 # the dimensionality of the character embedding vectors\n",
        "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
        "\n",
        "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
        "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
        "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g)*(5/3)/((n_embd * block_size)**0.5)\n",
        "b1 = torch.randn(n_hidden,                        generator=g)*0.01\n",
        "W2 = torch.randn((n_hidden, vocab_size),          generator=g)* 0.01\n",
        "b2 = torch.randn(vocab_size,                      generator=g)*0.0\n",
        "\n",
        "\n",
        "parameters = [C, W1,b1, W2, b2]\n",
        "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
        "for p in parameters:\n",
        "  p.requires_grad = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGNMqtKL8YR-",
        "outputId": "a3a7a152-bb18-4507-e34b-5da47c9aef9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hpreact.mean(0,keepdims=True).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-b3SXrHmRAhv",
        "outputId": "297aa756-3a13-40cc-d645-8980d26f2568"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# same optimization as last time\n",
        "max_steps = 200000\n",
        "batch_size = 32\n",
        "lossi = []\n",
        "\n",
        "for i in range(max_steps):\n",
        "  \n",
        "  # minibatch construct\n",
        "  ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
        "  Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
        "  #print(Yb)\n",
        "  \n",
        "  # forward pass\n",
        "  emb = C[Xb] # embed the characters into vectors\n",
        "  embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
        "  # Linear layer\n",
        "  hpreact = embcat @ W1 + b1 \n",
        "  hpreact=(hpreact-hpreact.mean(0,keepdims=True))/(hpreact.std(0,keepdims=True))\n",
        "  # Non-linearity\n",
        "  h = torch.tanh(hpreact) # hidden layer\n",
        "  logits = h @ W2 + b2 # output layer\n",
        "  loss = F.cross_entropy(logits, Yb) # loss function\n",
        "  \n",
        "  # backward pass\n",
        "  for p in parameters:\n",
        "    p.grad = None\n",
        "  loss.backward()\n",
        "  \n",
        "  # update\n",
        "  lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
        "  for p in parameters:\n",
        "    p.data += -lr * p.grad\n",
        "\n",
        "  # track stats\n",
        "  if i % 10000 == 0: # print every once in a while\n",
        "    print(f'{i:2d}/{max_steps:2d}: {loss.item():.4f}')\n",
        "  lossi.append(loss.log10().item())\n",
        "\n",
        "  #break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgl8b0er87yV",
        "outputId": "d2759bed-d08c-4f07-c205-89c6b90fa2a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0/200000: 3.3179\n",
            "10000/200000: 2.1910\n",
            "20000/200000: 2.3270\n",
            "30000/200000: 2.5396\n",
            "40000/200000: 1.9468\n",
            "50000/200000: 2.3331\n",
            "60000/200000: 2.3852\n",
            "70000/200000: 2.1173\n",
            "80000/200000: 2.3159\n",
            "90000/200000: 2.2010\n",
            "100000/200000: 1.8591\n",
            "110000/200000: 2.0881\n",
            "120000/200000: 1.9389\n",
            "130000/200000: 2.3913\n",
            "140000/200000: 2.0949\n",
            "150000/200000: 2.1458\n",
            "160000/200000: 1.7824\n",
            "170000/200000: 1.7249\n",
            "180000/200000: 1.9752\n",
            "190000/200000: 1.8614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### As we can see, the loss on initialisation is very high and subsequent losses are no where near that value. This shouldn't be the case ideally. On initialisation, every character should have equally likely chance of getting picked up but this high loss value indicates that some characters are more probable of getting picked up than others."
      ],
      "metadata": {
        "id": "B9_Srh8t-5vX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ideally the probabilities will be equally likely and equal to 1/27"
      ],
      "metadata": {
        "id": "AEkMhqhwARg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## The ideal loss on initialisation should be \n",
        "\n",
        "(-torch.tensor(1/27).log())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1mLGZAYAjbM",
        "outputId": "4a9143b8-6943-4264-e7f7-3ba91c978124"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.2958)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A four dimensional example. Assuming the target label is 2\n",
        "logits=torch.tensor([0.0,0.0,0.0,0.0,0.0])\n",
        "probs=torch.softmax(logits,dim=0)\n",
        "loss=-probs[2].log()\n",
        "probs,loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtF9Xz34BKeV",
        "outputId": "c960c520-1b9b-4cc5-8842-92c5784466cf"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000]), tensor(1.6094))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If we change numbers from 0, we will get more loss and if we keep every number close to 0, we will get less loss"
      ],
      "metadata": {
        "id": "dx33rSB6KaLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(lossi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "qk9vR4qY-PVw",
        "outputId": "54cea959-fee2-4f53-a243-ceb63df088d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9e91a3b9a0>]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad() # this decorator disables gradient tracking for efficiency reasons\n",
        "def split_loss(split):\n",
        "  x,y = {\n",
        "    'train': (Xtr, Ytr),\n",
        "    'val': (Xdev, Ydev),\n",
        "    'test': (Xte, Yte),\n",
        "  }[split]\n",
        "  emb = C[x] # (N, block_size, n_embd)\n",
        "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
        "  h = torch.tanh(embcat@W1+b1) # (N, n_hidden)\n",
        "  logits = h @ W2 + b2 # (N, vocab_size)\n",
        "  loss = F.cross_entropy(logits, y)\n",
        "  print(split, loss.item())\n",
        "\n",
        "split_loss('train')\n",
        "split_loss('val')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QcJ2XDT_7PI",
        "outputId": "fdaf14ae-cdaa-4d18-c385-835e94cfff64"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train 2.0376641750335693\n",
            "val 2.106989622116089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss log\n",
        "original:\n",
        "train 2.1245384216308594 val 2.1750576496124268\n",
        "\n",
        "fix softmax confidently wrong:\n",
        "train 2.07 val 2.13 (we achieved this by fixing our initialisation loss which we achieved by setting b2 to 0 and reducing W2 values) We did this because, at initialisation, we were getting a very high loss value. Getting high loss is not possible because during initialisation, every character is equally probable and the neural network does favour any particular character.\n",
        "\n",
        "fix tanh layer too saturated at init: train 2.0355966091156006 val 2.1026785373687744 :We scaled down value of hpreact. This was done because h which we obtain after passing preact to tanh was producing a lot of -1 and 1 values. This can kill gradients.\n",
        "\n",
        "using kaiming init formula for initialisation: we get train 2.0376641750335693\n",
        "val 2.106989622116089. Motivation is that we want to have similar gaussian distribution throughout the network and it should happen that after some operations, distribution is changing\n"
      ],
      "metadata": {
        "id": "xFDKcZZ2W9d8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sample from the model\n",
        "g = torch.Generator().manual_seed(2147483647 + 10)\n",
        "\n",
        "for _ in range(20):\n",
        "    \n",
        "    out = []\n",
        "    context = [0] * block_size # initialize with all ...\n",
        "    while True:\n",
        "      # forward pass the neural net\n",
        "      emb = C[torch.tensor([context])] # (1,block_size,n_embd)\n",
        "      h = torch.tanh(emb.view(1, -1)@W1+b1) # concatenate the vectors\n",
        "      logits=h@W2+b2\n",
        "      probs = F.softmax(logits, dim=1)\n",
        "      # sample from the distribution\n",
        "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
        "      # shift the context window and track the samples\n",
        "      context = context[1:] + [ix]\n",
        "      out.append(ix)\n",
        "      # if we sample the special '.' token, break\n",
        "      if ix == 0:\n",
        "        break\n",
        "    \n",
        "    print(''.join(itos[i] for i in out)) # decode and print the generated word"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7xum_F-AVnQ",
        "outputId": "086fbbe1-f8c5-44b9-d6e2-4078cc6916cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "carlah.\n",
            "amille.\n",
            "khy.\n",
            "myli.\n",
            "taty.\n",
            "skanden.\n",
            "jazonen.\n",
            "amerynchireei.\n",
            "nellara.\n",
            "chaiir.\n",
            "kaleigh.\n",
            "ham.\n",
            "jorn.\n",
            "quint.\n",
            "salin.\n",
            "alianni.\n",
            "wanthoniearyn.\n",
            "kai.\n",
            "everusabee.\n",
            "demiia.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hq5y7u0wCa4J"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}